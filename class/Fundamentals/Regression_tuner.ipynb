{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MartaCaste/Master-Big-Data/blob/main/class/Fundamentals/Regression_tuner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f310246",
      "metadata": {
        "id": "5f310246"
      },
      "source": [
        "It is highly recommended to use a powerful **GPU**, you can use it for free uploading this notebook to [Google Colab](https://colab.research.google.com/notebooks/intro.ipynb).\n",
        "<table align=\"center\">\n",
        " <td align=\"center\"><a target=\"_blank\" href=\"https://colab.research.google.com/github/ezponda/intro_deep_learning/blob/main/class/Fundamentals/Regression_tuner.ipynb\">\n",
        "        <img src=\"https://i.ibb.co/2P3SLwK/colab.png\"  style=\"padding-bottom:5px;\" />Run in Google Colab</a></td>\n",
        "  <td align=\"center\"><a target=\"_blank\" href=\"https://github.com/ezponda/intro_deep_learning/blob/main/class/Fundamentals/Regression_tuner.ipynb\">\n",
        "        <img src=\"https://i.ibb.co/xfJbPmL/github.png\"  height=\"70px\" style=\"padding-bottom:5px;\"  />View Source on GitHub</a></td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "2360c95e",
      "metadata": {
        "id": "2360c95e"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b45e3013",
      "metadata": {
        "id": "b45e3013"
      },
      "source": [
        "# Abalone Dataset\n",
        "\n",
        "Abalones are marine snails that can be found along coasts of almost every continent. \n",
        "\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/0/0b/AbaloneInside.jpg/440px-AbaloneInside.jpg\" alt=\"abalone\" border=\"0\" width=\"400\" height=\"500\">\n",
        "\n",
        "\n",
        "\n",
        "In this notebook we are going to Predict the age of abalone from physical measurements. [Link to documentation](https://archive.ics.uci.edu/ml/datasets/abalone)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "801c6c84",
      "metadata": {
        "scrolled": true,
        "id": "801c6c84",
        "outputId": "0cfdd29f-3e98-450c-d4b3-9cccfeb8dbb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Length  Diameter  Height  Whole weight  Shucked weight  Viscera weight  \\\n",
              "0   0.435     0.335   0.110         0.334          0.1355          0.0775   \n",
              "1   0.585     0.450   0.125         0.874          0.3545          0.2075   \n",
              "2   0.655     0.510   0.160         1.092          0.3960          0.2825   \n",
              "3   0.545     0.425   0.125         0.768          0.2940          0.1495   \n",
              "4   0.545     0.420   0.130         0.879          0.3740          0.1695   \n",
              "\n",
              "   Shell weight  Age  \n",
              "0        0.0965    7  \n",
              "1        0.2250    6  \n",
              "2        0.3700   14  \n",
              "3        0.2600   16  \n",
              "4        0.2300   13  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-34c08213-67a3-43bb-b229-f0644b6b063f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Length</th>\n",
              "      <th>Diameter</th>\n",
              "      <th>Height</th>\n",
              "      <th>Whole weight</th>\n",
              "      <th>Shucked weight</th>\n",
              "      <th>Viscera weight</th>\n",
              "      <th>Shell weight</th>\n",
              "      <th>Age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.435</td>\n",
              "      <td>0.335</td>\n",
              "      <td>0.110</td>\n",
              "      <td>0.334</td>\n",
              "      <td>0.1355</td>\n",
              "      <td>0.0775</td>\n",
              "      <td>0.0965</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.585</td>\n",
              "      <td>0.450</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.874</td>\n",
              "      <td>0.3545</td>\n",
              "      <td>0.2075</td>\n",
              "      <td>0.2250</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.655</td>\n",
              "      <td>0.510</td>\n",
              "      <td>0.160</td>\n",
              "      <td>1.092</td>\n",
              "      <td>0.3960</td>\n",
              "      <td>0.2825</td>\n",
              "      <td>0.3700</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.545</td>\n",
              "      <td>0.425</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.768</td>\n",
              "      <td>0.2940</td>\n",
              "      <td>0.1495</td>\n",
              "      <td>0.2600</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.545</td>\n",
              "      <td>0.420</td>\n",
              "      <td>0.130</td>\n",
              "      <td>0.879</td>\n",
              "      <td>0.3740</td>\n",
              "      <td>0.1695</td>\n",
              "      <td>0.2300</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-34c08213-67a3-43bb-b229-f0644b6b063f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-34c08213-67a3-43bb-b229-f0644b6b063f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-34c08213-67a3-43bb-b229-f0644b6b063f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "df_train = pd.read_csv(\n",
        "    \"https://storage.googleapis.com/download.tensorflow.org/data/abalone_train.csv\",\n",
        "    names=[\"Length\", \"Diameter\", \"Height\", \"Whole weight\", \"Shucked weight\",\n",
        "           \"Viscera weight\", \"Shell weight\", \"Age\"])\n",
        "df_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos a querer describir la edad de los abalones, la edad es un dato continuo por lo tanto el problema tratará de una regresion."
      ],
      "metadata": {
        "id": "Ae13FtYgmrST"
      },
      "id": "Ae13FtYgmrST"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "9edcad0b",
      "metadata": {
        "id": "9edcad0b",
        "outputId": "ea23eda2-3599-488e-dc43-9aeffc332109",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Length     Diameter       Height  Whole weight  Shucked weight  \\\n",
              "count  3320.000000  3320.000000  3320.000000   3320.000000     3320.000000   \n",
              "mean      0.522693     0.406575     0.139271      0.824734        0.357705   \n",
              "std       0.121164     0.100120     0.042708      0.491182        0.222223   \n",
              "min       0.075000     0.055000     0.000000      0.002000        0.001000   \n",
              "25%       0.450000     0.345000     0.115000      0.436375        0.181500   \n",
              "50%       0.540000     0.425000     0.140000      0.795250        0.335500   \n",
              "75%       0.615000     0.480000     0.165000      1.150000        0.504500   \n",
              "max       0.815000     0.650000     1.130000      2.825500        1.488000   \n",
              "\n",
              "       Viscera weight  Shell weight          Age  \n",
              "count     3320.000000   3320.000000  3320.000000  \n",
              "mean         0.180162      0.237921     9.896988  \n",
              "std          0.110182      0.140261     3.205654  \n",
              "min          0.000500      0.001500     1.000000  \n",
              "25%          0.092000      0.127375     8.000000  \n",
              "50%          0.170750      0.230000     9.000000  \n",
              "75%          0.253125      0.325000    11.000000  \n",
              "max          0.760000      1.005000    27.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-67386959-8093-4562-b6e8-1f241e8edd75\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Length</th>\n",
              "      <th>Diameter</th>\n",
              "      <th>Height</th>\n",
              "      <th>Whole weight</th>\n",
              "      <th>Shucked weight</th>\n",
              "      <th>Viscera weight</th>\n",
              "      <th>Shell weight</th>\n",
              "      <th>Age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>3320.000000</td>\n",
              "      <td>3320.000000</td>\n",
              "      <td>3320.000000</td>\n",
              "      <td>3320.000000</td>\n",
              "      <td>3320.000000</td>\n",
              "      <td>3320.000000</td>\n",
              "      <td>3320.000000</td>\n",
              "      <td>3320.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.522693</td>\n",
              "      <td>0.406575</td>\n",
              "      <td>0.139271</td>\n",
              "      <td>0.824734</td>\n",
              "      <td>0.357705</td>\n",
              "      <td>0.180162</td>\n",
              "      <td>0.237921</td>\n",
              "      <td>9.896988</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.121164</td>\n",
              "      <td>0.100120</td>\n",
              "      <td>0.042708</td>\n",
              "      <td>0.491182</td>\n",
              "      <td>0.222223</td>\n",
              "      <td>0.110182</td>\n",
              "      <td>0.140261</td>\n",
              "      <td>3.205654</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.075000</td>\n",
              "      <td>0.055000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002000</td>\n",
              "      <td>0.001000</td>\n",
              "      <td>0.000500</td>\n",
              "      <td>0.001500</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.450000</td>\n",
              "      <td>0.345000</td>\n",
              "      <td>0.115000</td>\n",
              "      <td>0.436375</td>\n",
              "      <td>0.181500</td>\n",
              "      <td>0.092000</td>\n",
              "      <td>0.127375</td>\n",
              "      <td>8.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.540000</td>\n",
              "      <td>0.425000</td>\n",
              "      <td>0.140000</td>\n",
              "      <td>0.795250</td>\n",
              "      <td>0.335500</td>\n",
              "      <td>0.170750</td>\n",
              "      <td>0.230000</td>\n",
              "      <td>9.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.615000</td>\n",
              "      <td>0.480000</td>\n",
              "      <td>0.165000</td>\n",
              "      <td>1.150000</td>\n",
              "      <td>0.504500</td>\n",
              "      <td>0.253125</td>\n",
              "      <td>0.325000</td>\n",
              "      <td>11.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.815000</td>\n",
              "      <td>0.650000</td>\n",
              "      <td>1.130000</td>\n",
              "      <td>2.825500</td>\n",
              "      <td>1.488000</td>\n",
              "      <td>0.760000</td>\n",
              "      <td>1.005000</td>\n",
              "      <td>27.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-67386959-8093-4562-b6e8-1f241e8edd75')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-67386959-8093-4562-b6e8-1f241e8edd75 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-67386959-8093-4562-b6e8-1f241e8edd75');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "df_train.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "3c554e97",
      "metadata": {
        "id": "3c554e97"
      },
      "outputs": [],
      "source": [
        "y_train = df_train.pop('Age')\n",
        "X_train = df_train.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "con df_train.pop quitamos la columna que queremos predecir y dejamos el resto. A continuacion nos descargamos el data set del test "
      ],
      "metadata": {
        "id": "5ItXmfiem9hl"
      },
      "id": "5ItXmfiem9hl"
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "k9HreJ_rmqAU"
      },
      "id": "k9HreJ_rmqAU"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "fede61bd",
      "metadata": {
        "id": "fede61bd"
      },
      "outputs": [],
      "source": [
        "df_test = pd.read_csv(\n",
        "    \"https://storage.googleapis.com/download.tensorflow.org/data/abalone_test.csv\",\n",
        "    names=[\"Length\", \"Diameter\", \"Height\", \"Whole weight\", \"Shucked weight\",\n",
        "           \"Viscera weight\", \"Shell weight\", \"Age\"])\n",
        "y_test = df_test.pop('Age')\n",
        "X_test = df_test.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "de841977",
      "metadata": {
        "id": "de841977",
        "outputId": "883b4dac-da1e-48f9-fa0f-fb9f39ca46e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (3320, 7), X_test shape: (850, 7)\n"
          ]
        }
      ],
      "source": [
        "print(f'X_train shape: {X_train.shape}, X_test shape: {X_test.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a1bf8de",
      "metadata": {
        "id": "4a1bf8de"
      },
      "source": [
        "## Regression Losses\n",
        "\n",
        "- **Mean Squared Error (MSE)**: \n",
        "\n",
        "```python\n",
        "tf.keras.losses.MSE\n",
        "```\n",
        "```python\n",
        "model.compile(loss='mse') or model.compile(loss=tf.keras.losses.MSE)\n",
        "```\n",
        "\n",
        "$$ \\mathrm{MSE} = \\frac{\\sum_{i=1}^n\\left( y_i - \\hat{y_i}\\right)^2}{n}$$\n",
        "\n",
        "\n",
        "- **Mean Absolute Error (MAE)**: \n",
        "\n",
        "```python\n",
        "tf.keras.losses.MAE\n",
        "```\n",
        "```python\n",
        "model.compile(loss='mae') or model.compile(loss=tf.keras.losses.MAE)\n",
        "```\n",
        "\n",
        "$$ \\mathrm{MAE} = \\frac{\\sum_{i=1}^n\\left| y_i - \\hat{y_i}\\right|}{n}$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "313693e1",
      "metadata": {
        "id": "313693e1"
      },
      "source": [
        "## Question 1: Create a sequential net with at least 1 hidden layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "0f142132",
      "metadata": {
        "id": "0f142132",
        "outputId": "6b4f6101-5ff7-4408-8c7a-4e17f3140f09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_16 (Dense)            (None, 4)                 32        \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 1)                 5         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 37\n",
            "Trainable params: 37\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "model.add(layers.Dense(4, input_shape=(7,), activation='relu'))\n",
        "\n",
        "# output layer\n",
        "model.add(layers.Dense(1, activation='relu'))\n",
        "\n",
        "## model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "26bb1a7b",
      "metadata": {
        "scrolled": true,
        "id": "26bb1a7b",
        "outputId": "9e8e9ee6-68ff-44f2-c22e-d8851811184e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 6.7355 - mae: 1.8807 - val_loss: 6.6827 - val_mae: 1.9075\n",
            "Epoch 2/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 6.7026 - mae: 1.8650 - val_loss: 6.6422 - val_mae: 1.9225\n",
            "Epoch 3/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 6.6687 - mae: 1.8725 - val_loss: 6.6114 - val_mae: 1.9111\n",
            "Epoch 4/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 6.6370 - mae: 1.8578 - val_loss: 6.5837 - val_mae: 1.9046\n",
            "Epoch 5/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 6.6037 - mae: 1.8622 - val_loss: 6.5535 - val_mae: 1.9079\n",
            "Epoch 6/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 6.5754 - mae: 1.8527 - val_loss: 6.5277 - val_mae: 1.9030\n",
            "Epoch 7/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 6.5491 - mae: 1.8588 - val_loss: 6.5066 - val_mae: 1.8931\n",
            "Epoch 8/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 6.5178 - mae: 1.8513 - val_loss: 6.4805 - val_mae: 1.8889\n",
            "Epoch 9/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 6.4910 - mae: 1.8502 - val_loss: 6.4637 - val_mae: 1.8750\n",
            "Epoch 10/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 6.4646 - mae: 1.8441 - val_loss: 6.4356 - val_mae: 1.8740\n",
            "Epoch 11/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 6.4343 - mae: 1.8248 - val_loss: 6.4033 - val_mae: 1.8913\n",
            "Epoch 12/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 6.4138 - mae: 1.8491 - val_loss: 6.3900 - val_mae: 1.8684\n",
            "Epoch 13/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 6.3848 - mae: 1.8317 - val_loss: 6.3636 - val_mae: 1.8672\n",
            "Epoch 14/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 6.3571 - mae: 1.8269 - val_loss: 6.3371 - val_mae: 1.8717\n",
            "Epoch 15/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 6.3362 - mae: 1.8162 - val_loss: 6.3147 - val_mae: 1.8753\n",
            "Epoch 16/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 6.3098 - mae: 1.8244 - val_loss: 6.2933 - val_mae: 1.8709\n",
            "Epoch 17/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 6.2846 - mae: 1.8173 - val_loss: 6.2749 - val_mae: 1.8665\n",
            "Epoch 18/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 6.2610 - mae: 1.8243 - val_loss: 6.2617 - val_mae: 1.8470\n",
            "Epoch 19/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 6.2350 - mae: 1.8065 - val_loss: 6.2294 - val_mae: 1.8555\n",
            "Epoch 20/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 6.2135 - mae: 1.8065 - val_loss: 6.2175 - val_mae: 1.8410\n",
            "Epoch 21/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 6.1894 - mae: 1.8088 - val_loss: 6.1990 - val_mae: 1.8364\n",
            "Epoch 22/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 6.1655 - mae: 1.7942 - val_loss: 6.1722 - val_mae: 1.8414\n",
            "Epoch 23/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 6.1432 - mae: 1.8078 - val_loss: 6.1540 - val_mae: 1.8337\n",
            "Epoch 24/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 6.1234 - mae: 1.7864 - val_loss: 6.1293 - val_mae: 1.8382\n",
            "Epoch 25/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 6.1005 - mae: 1.7947 - val_loss: 6.1221 - val_mae: 1.8233\n",
            "Epoch 26/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 6.0774 - mae: 1.7838 - val_loss: 6.0891 - val_mae: 1.8402\n",
            "Epoch 27/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 6.0519 - mae: 1.7829 - val_loss: 6.0722 - val_mae: 1.8263\n",
            "Epoch 28/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 6.0320 - mae: 1.7824 - val_loss: 6.0531 - val_mae: 1.8251\n",
            "Epoch 29/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 6.0091 - mae: 1.7761 - val_loss: 6.0416 - val_mae: 1.8114\n",
            "Epoch 30/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 5.9930 - mae: 1.7728 - val_loss: 6.0120 - val_mae: 1.8170\n",
            "Epoch 31/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 5.9689 - mae: 1.7725 - val_loss: 5.9963 - val_mae: 1.8160\n",
            "Epoch 32/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 5.9493 - mae: 1.7762 - val_loss: 5.9877 - val_mae: 1.8012\n",
            "Epoch 33/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 5.9294 - mae: 1.7681 - val_loss: 5.9671 - val_mae: 1.7979\n",
            "Epoch 34/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 5.9089 - mae: 1.7657 - val_loss: 5.9618 - val_mae: 1.7879\n",
            "Epoch 35/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 5.8891 - mae: 1.7560 - val_loss: 5.9232 - val_mae: 1.8038\n",
            "Epoch 36/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 5.8712 - mae: 1.7568 - val_loss: 5.9249 - val_mae: 1.7791\n",
            "Epoch 37/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 5.8530 - mae: 1.7533 - val_loss: 5.8962 - val_mae: 1.7876\n",
            "Epoch 38/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 5.8281 - mae: 1.7450 - val_loss: 5.8769 - val_mae: 1.7853\n",
            "Epoch 39/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 5.8101 - mae: 1.7489 - val_loss: 5.8520 - val_mae: 1.7946\n",
            "Epoch 40/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 5.7873 - mae: 1.7521 - val_loss: 5.8484 - val_mae: 1.7736\n",
            "Epoch 41/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 5.7653 - mae: 1.7315 - val_loss: 5.8203 - val_mae: 1.7966\n",
            "Epoch 42/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 5.7521 - mae: 1.7455 - val_loss: 5.8123 - val_mae: 1.7747\n",
            "Epoch 43/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 5.7340 - mae: 1.7421 - val_loss: 5.8027 - val_mae: 1.7612\n",
            "Epoch 44/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 5.7152 - mae: 1.7257 - val_loss: 5.7754 - val_mae: 1.7755\n",
            "Epoch 45/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 5.6954 - mae: 1.7395 - val_loss: 5.7877 - val_mae: 1.7448\n",
            "Epoch 46/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 5.6862 - mae: 1.7304 - val_loss: 5.7772 - val_mae: 1.7395\n",
            "Epoch 47/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 5.6589 - mae: 1.7126 - val_loss: 5.7252 - val_mae: 1.7664\n",
            "Epoch 48/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 5.6440 - mae: 1.7233 - val_loss: 5.7073 - val_mae: 1.7662\n",
            "Epoch 49/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 5.6252 - mae: 1.7206 - val_loss: 5.6961 - val_mae: 1.7551\n",
            "Epoch 50/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 5.6024 - mae: 1.7194 - val_loss: 5.6792 - val_mae: 1.7482\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4fed1a8e50>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss=tf.keras.losses.MSE,\n",
        "    metrics=['mae']\n",
        ")\n",
        "model.fit(X_train, y_train, epochs=50, validation_split=0.2, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "644f80fd",
      "metadata": {
        "id": "644f80fd",
        "outputId": "5a5e9e00-2e48-46cf-a46e-a19cf1397ba5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27/27 [==============================] - 0s 1ms/step - loss: 6.1874 - mae: 1.7454\n",
            "Test Loss: 6.187387466430664\n"
          ]
        }
      ],
      "source": [
        "results = model.evaluate(X_test, y_test, verbose=1)\n",
        "print('Test Loss: {}'.format(results[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c909754",
      "metadata": {
        "id": "5c909754"
      },
      "source": [
        "## Question 2: Normalize the inputs and train the same model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "d9ed6000",
      "metadata": {
        "id": "d9ed6000",
        "outputId": "847ae2bd-806a-43ee-847e-b2ebd45aecfe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train mu, sigma Length            0.522693\n",
            "Diameter          0.406575\n",
            "Height            0.139271\n",
            "Whole weight      0.824734\n",
            "Shucked weight    0.357705\n",
            "Viscera weight    0.180162\n",
            "Shell weight      0.237921\n",
            "dtype: float64 Length            0.121164\n",
            "Diameter          0.100120\n",
            "Height            0.042708\n",
            "Whole weight      0.491182\n",
            "Shucked weight    0.222223\n",
            "Viscera weight    0.110182\n",
            "Shell weight      0.140261\n",
            "dtype: float64\n",
            "X_test mu, sigma Length            0.529729\n",
            "Diameter          0.413500\n",
            "Height            0.140594\n",
            "Whole weight      0.846645\n",
            "Shucked weight    0.366949\n",
            "Viscera weight    0.182829\n",
            "Shell weight      0.242852\n",
            "dtype: float64 Length            0.115384\n",
            "Diameter          0.095291\n",
            "Height            0.038153\n",
            "Whole weight      0.487582\n",
            "Shucked weight    0.221109\n",
            "Viscera weight    0.107469\n",
            "Shell weight      0.135136\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train_norm = df_train.copy()\n",
        "X_test_norm = df_test.copy()\n",
        "print('X_train mu, sigma', X_train_norm.mean(0), X_train_norm.std(0))\n",
        "print('X_test mu, sigma', X_test_norm.mean(0), X_test_norm.std(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "16ac44c0",
      "metadata": {
        "id": "16ac44c0",
        "outputId": "84358ae2-1005-41c1-ac67-c0e88225ffa0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_18 (Dense)            (None, 4)                 32        \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 1)                 5         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 37\n",
            "Trainable params: 37\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = keras.Sequential()\n",
        "\n",
        "model.add(layers.Dense(4, input_shape=(7,), activation='relu'))\n",
        "\n",
        "# output layer\n",
        "model.add(layers.Dense(1, activation='relu'))\n",
        "## model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "173bef88",
      "metadata": {
        "id": "173bef88",
        "outputId": "a3daf8f2-7aee-4633-bac5-d3d04a930a6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 95.6162 - mae: 9.2818 - val_loss: 90.7562 - val_mae: 9.0280\n",
            "Epoch 2/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 85.3356 - mae: 8.7379 - val_loss: 79.4678 - val_mae: 8.4107\n",
            "Epoch 3/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 73.0609 - mae: 8.0363 - val_loss: 66.5948 - val_mae: 7.6434\n",
            "Epoch 4/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 59.7170 - mae: 7.1899 - val_loss: 53.1809 - val_mae: 6.7458\n",
            "Epoch 5/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 46.4850 - mae: 6.2348 - val_loss: 40.4993 - val_mae: 5.7601\n",
            "Epoch 6/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 34.5823 - mae: 5.2209 - val_loss: 29.6811 - val_mae: 4.7490\n",
            "Epoch 7/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 24.9577 - mae: 4.2107 - val_loss: 21.3267 - val_mae: 3.7807\n",
            "Epoch 8/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 18.0108 - mae: 3.3380 - val_loss: 15.6680 - val_mae: 3.0366\n",
            "Epoch 9/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 13.5640 - mae: 2.7232 - val_loss: 12.2521 - val_mae: 2.5972\n",
            "Epoch 10/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 11.0678 - mae: 2.3851 - val_loss: 10.4274 - val_mae: 2.3633\n",
            "Epoch 11/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 9.8377 - mae: 2.2373 - val_loss: 9.5519 - val_mae: 2.2701\n",
            "Epoch 12/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 9.2905 - mae: 2.1843 - val_loss: 9.1589 - val_mae: 2.2287\n",
            "Epoch 13/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 9.0383 - mae: 2.1644 - val_loss: 8.9573 - val_mae: 2.2077\n",
            "Epoch 14/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 8.9041 - mae: 2.1577 - val_loss: 8.8373 - val_mae: 2.1943\n",
            "Epoch 15/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 8.8111 - mae: 2.1482 - val_loss: 8.7428 - val_mae: 2.1812\n",
            "Epoch 16/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 8.7303 - mae: 2.1390 - val_loss: 8.6591 - val_mae: 2.1685\n",
            "Epoch 17/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 8.6518 - mae: 2.1280 - val_loss: 8.5780 - val_mae: 2.1559\n",
            "Epoch 18/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 8.5742 - mae: 2.1166 - val_loss: 8.5002 - val_mae: 2.1421\n",
            "Epoch 19/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 8.4954 - mae: 2.1057 - val_loss: 8.4180 - val_mae: 2.1293\n",
            "Epoch 20/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 8.4175 - mae: 2.0909 - val_loss: 8.3376 - val_mae: 2.1161\n",
            "Epoch 21/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 8.3396 - mae: 2.0800 - val_loss: 8.2599 - val_mae: 2.1025\n",
            "Epoch 22/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 8.2622 - mae: 2.0701 - val_loss: 8.1813 - val_mae: 2.0908\n",
            "Epoch 23/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 8.1822 - mae: 2.0553 - val_loss: 8.1045 - val_mae: 2.0786\n",
            "Epoch 24/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 8.1096 - mae: 2.0471 - val_loss: 8.0269 - val_mae: 2.0674\n",
            "Epoch 25/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 8.0306 - mae: 2.0336 - val_loss: 7.9527 - val_mae: 2.0557\n",
            "Epoch 26/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 7.9578 - mae: 2.0269 - val_loss: 7.8765 - val_mae: 2.0459\n",
            "Epoch 27/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 7.8849 - mae: 2.0127 - val_loss: 7.8070 - val_mae: 2.0336\n",
            "Epoch 28/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 7.8146 - mae: 2.0010 - val_loss: 7.7349 - val_mae: 2.0241\n",
            "Epoch 29/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 7.7426 - mae: 1.9933 - val_loss: 7.6635 - val_mae: 2.0185\n",
            "Epoch 30/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 7.6770 - mae: 1.9821 - val_loss: 7.5947 - val_mae: 2.0115\n",
            "Epoch 31/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 7.6110 - mae: 1.9815 - val_loss: 7.5330 - val_mae: 1.9993\n",
            "Epoch 32/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 7.5459 - mae: 1.9646 - val_loss: 7.4681 - val_mae: 1.9944\n",
            "Epoch 33/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 7.4845 - mae: 1.9567 - val_loss: 7.4092 - val_mae: 1.9865\n",
            "Epoch 34/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 7.4253 - mae: 1.9549 - val_loss: 7.3521 - val_mae: 1.9814\n",
            "Epoch 35/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 7.3686 - mae: 1.9432 - val_loss: 7.2975 - val_mae: 1.9721\n",
            "Epoch 36/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 7.3146 - mae: 1.9289 - val_loss: 7.2390 - val_mae: 1.9759\n",
            "Epoch 37/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 7.2629 - mae: 1.9337 - val_loss: 7.1889 - val_mae: 1.9670\n",
            "Epoch 38/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 7.2142 - mae: 1.9260 - val_loss: 7.1384 - val_mae: 1.9650\n",
            "Epoch 39/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 7.1664 - mae: 1.9216 - val_loss: 7.0957 - val_mae: 1.9582\n",
            "Epoch 40/50\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 7.1210 - mae: 1.9103 - val_loss: 7.0561 - val_mae: 1.9490\n",
            "Epoch 41/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 7.0788 - mae: 1.9137 - val_loss: 7.0085 - val_mae: 1.9531\n",
            "Epoch 42/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 7.0405 - mae: 1.9056 - val_loss: 6.9689 - val_mae: 1.9479\n",
            "Epoch 43/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 6.9986 - mae: 1.9081 - val_loss: 6.9410 - val_mae: 1.9320\n",
            "Epoch 44/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 6.9650 - mae: 1.8946 - val_loss: 6.9039 - val_mae: 1.9295\n",
            "Epoch 45/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 6.9258 - mae: 1.8948 - val_loss: 6.8661 - val_mae: 1.9346\n",
            "Epoch 46/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 6.8971 - mae: 1.8843 - val_loss: 6.8312 - val_mae: 1.9329\n",
            "Epoch 47/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 6.8617 - mae: 1.8867 - val_loss: 6.7987 - val_mae: 1.9307\n",
            "Epoch 48/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 6.8284 - mae: 1.8928 - val_loss: 6.7724 - val_mae: 1.9190\n",
            "Epoch 49/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 6.8014 - mae: 1.8808 - val_loss: 6.7396 - val_mae: 1.9253\n",
            "Epoch 50/50\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 6.7688 - mae: 1.8765 - val_loss: 6.7119 - val_mae: 1.9169\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4fdf3b75d0>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss=tf.keras.losses.MSE,\n",
        "    metrics=['mae']\n",
        ")\n",
        "model.fit(X_train_norm, y_train, epochs=50, validation_split=0.2, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "e6040ce5",
      "metadata": {
        "id": "e6040ce5",
        "outputId": "147545e7-1fb8-4f32-ff9f-f61f535a2e00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27/27 [==============================] - 0s 1ms/step - loss: 7.2444 - mae: 1.9114\n",
            "Test Loss: 7.2443928718566895\n"
          ]
        }
      ],
      "source": [
        "results = model.evaluate(X_test_norm, y_test, verbose=1)\n",
        "print('Test Loss: {}'.format(results[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de862aa9",
      "metadata": {
        "id": "de862aa9"
      },
      "source": [
        "## Optimizers:\n",
        "\n",
        "- [SGD](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/SGD): Gradient descent with momentum\n",
        "```python\n",
        "tf.keras.optimizers.SGD(\n",
        "    learning_rate=0.01, momentum=0.0, nesterov=False, name='SGD', **kwargs\n",
        ")\n",
        "```\n",
        "If momentum is 0:\n",
        "```python\n",
        "w = w - learning_rate * gradient\n",
        "```\n",
        "If we have momentum:\n",
        " \n",
        " ```python\n",
        "velocity = momentum * velocity - learning_rate * g\n",
        "w = w + velocity\n",
        "```\n",
        "\n",
        "\n",
        "- [RMSprop](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/RMSprop): Root Mean Square Propagation\n",
        "```python\n",
        "tf.keras.optimizers.RMSprop(\n",
        "    learning_rate=0.001, rho=0.9, momentum=0.0, epsilon=1e-07, centered=False,\n",
        "    name='RMSprop', **kwargs\n",
        ")\n",
        "```\n",
        "- [Adam](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam): Adaptive Moment Estimation,  is an update to the RMSProp algorithm\n",
        "```python\n",
        "tf.keras.optimizers.Adam(\n",
        "    learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,\n",
        "    name='Adam', **kwargs\n",
        ")\n",
        "```\n",
        "\n",
        "```python\n",
        "model.compile(loss='mse', optimizer='adam')\n",
        "model.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(learning_rate=0.001))\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d744232",
      "metadata": {
        "id": "0d744232"
      },
      "source": [
        "## Question 3: Train the same model with different optimizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17c797bd",
      "metadata": {
        "id": "17c797bd"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential()\n",
        "...\n",
        "## model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a81ef1a6",
      "metadata": {
        "id": "a81ef1a6"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer=...,\n",
        "    loss=...,\n",
        "    metrics=[...]\n",
        ")\n",
        "model.fit(X_train_norm, y_train, epochs=50, validation_split=0.2, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b36eaf75",
      "metadata": {
        "id": "b36eaf75"
      },
      "outputs": [],
      "source": [
        "results = model.evaluate(X_test_norm, y_test, verbose=1)\n",
        "print('Test Loss: {}'.format(results[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2377a7ff",
      "metadata": {
        "id": "2377a7ff"
      },
      "source": [
        "# Keras Tuner\n",
        "\n",
        "The [Keras Tuner](https://www.tensorflow.org/tutorials/keras/keras_tuner) is a library for hyper-parameter tuning.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "39e7af43",
      "metadata": {
        "id": "39e7af43",
        "outputId": "a5ef2e1a-7ba7-426b-9283-c9554cfd3ed3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.1.2-py3-none-any.whl (133 kB)\n",
            "\u001b[K     |████████████████████████████████| 133 kB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.8.0)\n",
            "Collecting kt-legacy\n",
            "  Downloading kt_legacy-1.0.4-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (21.3)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (5.5.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.21.6)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.4.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (2.6.1)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.8.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (57.4.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (5.1.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (1.0.18)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->keras-tuner) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->keras-tuner) (0.2.5)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->keras-tuner) (3.0.9)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->keras-tuner) (0.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2022.5.18.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.3.7)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.35.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.46.3)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.37.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.6.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.17.3)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.0.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->keras-tuner) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner) (4.2.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (3.2.0)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.1.2 kt-legacy-1.0.4\n"
          ]
        }
      ],
      "source": [
        "!pip install -U keras-tuner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "8f47d1f3",
      "metadata": {
        "id": "8f47d1f3",
        "outputId": "ce84fab1-91e8-4b5b-e81a-ff1c25d36ec1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ],
      "source": [
        "import kerastuner as kt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7e9b048",
      "metadata": {
        "id": "a7e9b048"
      },
      "source": [
        "Hyperparameters are of two types:\n",
        "1. **Model hyperparameters** like number of units, type of activation or number hidden layers.\n",
        "2. **Algorithm hyperparameters** like the learning rate in adam.\n",
        "\n",
        "The model-building function takes an argument `hp` from which you can sample hyper-parameters.\n",
        "\n",
        "```python\n",
        "def build_model(hp):\n",
        "    ...\n",
        "    return model\n",
        "\n",
        "```\n",
        "\n",
        "- `hp.Int` to sample an integer from a certain range:\n",
        "```python\n",
        "hp.Int('units', min_value=32, max_value=256, step=32, default=64)\n",
        "```\n",
        "- `hp.Float` to sample a float number from a certain range:\n",
        "```python\n",
        "hp.Float('dropout', min_value=0.0, max_value=0.1, default=0.005, step=0.05)\n",
        "```\n",
        "- `hp.Choice` to select values in a list:\n",
        "```python\n",
        "hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])\n",
        "```\n",
        "- [list of hyperparameter methods](https://keras-team.github.io/keras-tuner/documentation/hyperparameters/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "ef99c2b2",
      "metadata": {
        "id": "ef99c2b2"
      },
      "outputs": [],
      "source": [
        "def build_model(hp):\n",
        "    model = keras.Sequential()\n",
        "    # Sample different number of layers with hp.Int\n",
        "    for i in range(hp.Int('num_layers', 1, 3)):\n",
        "        # Sample different number of layers with hp.Int\n",
        "        model.add(layers.Dense(units=hp.Int('units_' + str(i),\n",
        "                                            min_value=32,\n",
        "                                            max_value=128,\n",
        "                                            step=32),\n",
        "                               activation='relu'))\n",
        "    # Sample different activation functions with hp.Choice \n",
        "    model.add(layers.Dense(1, activation=hp.Choice('output_activation', ['relu', 'linear'])))\n",
        "    \n",
        "    # Sample different activation functions with hp.Choice \n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(\n",
        "            hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])),\n",
        "        loss='mse',\n",
        "        metrics=['mae'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71047eeb",
      "metadata": {
        "id": "71047eeb"
      },
      "source": [
        "The Keras Tuner has four [tuners](https://keras-team.github.io/keras-tuner/documentation/tuners/) available  `RandomSearch`, `Hyperband`, `BayesianOptimization`, and `Sklearn`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "f8261f82",
      "metadata": {
        "id": "f8261f82"
      },
      "outputs": [],
      "source": [
        "tuner = kt.Hyperband(build_model,\n",
        "                     objective='val_loss',\n",
        "                     max_epochs=35,\n",
        "                     factor=2,\n",
        "                     hyperband_iterations=1,\n",
        "                     directory='my_dir',\n",
        "                     project_name='intro_to_kt')\n",
        "'''\n",
        "tuner = kt.RandomSearch(build_model,\n",
        "                     objective='val_loss',\n",
        "                     max_trials=100,\n",
        "                     directory='my_dir',\n",
        "                     project_name='intro_to_kt')\n",
        "'''\n",
        "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "322e674d",
      "metadata": {
        "id": "322e674d",
        "outputId": "a3dcea9c-0bbc-4dd9-9674-12d6d8ca4d07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 186 Complete [00h 00m 10s]\n",
            "val_loss: 6.746762752532959\n",
            "\n",
            "Best val_loss So Far: 4.634767532348633\n",
            "Total elapsed time: 00h 06m 47s\n",
            "INFO:tensorflow:Oracle triggered exit\n",
            "{'space': [{'class_name': 'Int', 'config': {'name': 'num_layers', 'default': None, 'conditions': [], 'min_value': 1, 'max_value': 3, 'step': 1, 'sampling': None}}, {'class_name': 'Int', 'config': {'name': 'units_0', 'default': None, 'conditions': [], 'min_value': 32, 'max_value': 128, 'step': 32, 'sampling': None}}, {'class_name': 'Choice', 'config': {'name': 'output_activation', 'default': 'relu', 'conditions': [], 'values': ['relu', 'linear'], 'ordered': False}}, {'class_name': 'Choice', 'config': {'name': 'learning_rate', 'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}}, {'class_name': 'Int', 'config': {'name': 'units_1', 'default': None, 'conditions': [], 'min_value': 32, 'max_value': 128, 'step': 32, 'sampling': None}}, {'class_name': 'Int', 'config': {'name': 'units_2', 'default': None, 'conditions': [], 'min_value': 32, 'max_value': 128, 'step': 32, 'sampling': None}}], 'values': {'num_layers': 3, 'units_0': 64, 'output_activation': 'linear', 'learning_rate': 0.001, 'units_1': 96, 'units_2': 32, 'tuner/epochs': 35, 'tuner/initial_epoch': 0, 'tuner/bracket': 0, 'tuner/round': 0}}\n"
          ]
        }
      ],
      "source": [
        "tuner.search(X_train_norm, y_train, epochs=30, validation_split=0.15, batch_size=32, callbacks=[stop_early])\n",
        "\n",
        "# Get the optimal hyperparameters\n",
        "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "print(best_hps.get_config())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "9d31a650",
      "metadata": {
        "id": "9d31a650",
        "outputId": "daa15994-2a43-4f9b-8233-4df72de6b148",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best learning rate: 0.001\n",
            "Best output activation function: linear\n",
            "Best number of hidden layers: 3\n",
            "Number of units of hidden layer 1: 64\n",
            "Number of units of hidden layer 2: 96\n",
            "Number of units of hidden layer 3: 32\n"
          ]
        }
      ],
      "source": [
        "print(f\"Best learning rate: {best_hps.get('learning_rate')}\")\n",
        "print(f\"Best output activation function: {best_hps.get('output_activation')}\")\n",
        "print(f\"Best number of hidden layers: {best_hps.get('num_layers')}\")\n",
        "for i in range(best_hps.get('num_layers')):\n",
        "    print(f\"Number of units of hidden layer {i+1}: {best_hps.get('units_' + str(i))}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6df9ffad",
      "metadata": {
        "id": "6df9ffad"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "5b439536",
      "metadata": {
        "id": "5b439536",
        "outputId": "4533df69-af3f-4df7-cc24-c3d1b7b23811",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "89/89 [==============================] - 1s 3ms/step - loss: 45.6538 - mae: 5.3222 - val_loss: 7.9710 - val_mae: 2.0347\n",
            "Epoch 2/50\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 6.8463 - mae: 1.8962 - val_loss: 6.7819 - val_mae: 1.9214\n",
            "Epoch 3/50\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 6.1045 - mae: 1.7983 - val_loss: 6.3010 - val_mae: 1.8465\n",
            "Epoch 4/50\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 5.5899 - mae: 1.7207 - val_loss: 6.0556 - val_mae: 1.7098\n",
            "Epoch 5/50\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 5.1646 - mae: 1.6482 - val_loss: 5.5424 - val_mae: 1.6751\n",
            "Epoch 6/50\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 4.8151 - mae: 1.6041 - val_loss: 5.3713 - val_mae: 1.7518\n",
            "Epoch 7/50\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 4.8061 - mae: 1.6189 - val_loss: 5.1837 - val_mae: 1.6169\n",
            "Epoch 8/50\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 4.7633 - mae: 1.5950 - val_loss: 5.4077 - val_mae: 1.5945\n",
            "Epoch 9/50\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 4.5946 - mae: 1.5749 - val_loss: 5.9870 - val_mae: 1.6630\n",
            "Epoch 10/50\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 4.6691 - mae: 1.5713 - val_loss: 5.1340 - val_mae: 1.5698\n",
            "Epoch 11/50\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 4.6370 - mae: 1.5811 - val_loss: 5.1959 - val_mae: 1.5694\n",
            "Epoch 12/50\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 4.5573 - mae: 1.5589 - val_loss: 4.9231 - val_mae: 1.6330\n",
            "Epoch 13/50\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 4.4885 - mae: 1.5525 - val_loss: 5.1559 - val_mae: 1.5590\n",
            "Epoch 14/50\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 4.5192 - mae: 1.5503 - val_loss: 4.9030 - val_mae: 1.6375\n",
            "Epoch 15/50\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 4.4960 - mae: 1.5424 - val_loss: 5.2564 - val_mae: 1.7942\n",
            "Epoch 16/50\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 4.5169 - mae: 1.5511 - val_loss: 5.2766 - val_mae: 1.5747\n",
            "Epoch 17/50\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 4.5373 - mae: 1.5543 - val_loss: 5.0367 - val_mae: 1.5584\n",
            "Epoch 18/50\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 4.4472 - mae: 1.5294 - val_loss: 4.9794 - val_mae: 1.7015\n",
            "Epoch 19/50\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 4.4504 - mae: 1.5343 - val_loss: 5.1933 - val_mae: 1.5594\n"
          ]
        }
      ],
      "source": [
        "model = tuner.hypermodel.build(best_hps)\n",
        "history = model.fit(X_train_norm, y_train, epochs=50, validation_split=0.15, callbacks=[stop_early])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "57509bd4",
      "metadata": {
        "id": "57509bd4",
        "outputId": "f9eb30eb-8e80-4287-abe1-72b6f1093afa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27/27 [==============================] - 0s 1ms/step - loss: 5.6370 - mae: 1.5609\n",
            "Test Loss: 5.6370158195495605\n"
          ]
        }
      ],
      "source": [
        "results = model.evaluate(X_test_norm, y_test, verbose=1)\n",
        "print('Test Loss: {}'.format(results[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6cbf5a27",
      "metadata": {
        "id": "6cbf5a27"
      },
      "source": [
        "## Question 4: Try to search with dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "659d9de9",
      "metadata": {
        "id": "659d9de9",
        "outputId": "396e33f0-ce36-4022-b7b1-afd2990e2124",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-3f7877bddbaa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m                      \u001b[0mhyperband_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                      \u001b[0mdirectory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'my_dir_2'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                      project_name='intro_to_kt')\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mstop_early\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_tuner/tuners/hyperband.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, hypermodel, objective, max_epochs, factor, hyperband_iterations, seed, hyperparameters, tune_new_entries, allow_new_entries, **kwargs)\u001b[0m\n\u001b[1;32m    374\u001b[0m         )\n\u001b[1;32m    375\u001b[0m         super(Hyperband, self).__init__(\n\u001b[0;32m--> 376\u001b[0;31m             \u001b[0moracle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhypermodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m         )\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/tuner.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, oracle, hypermodel, max_model_size, optimizer, loss, metrics, distribution_strategy, directory, project_name, logger, tuner_id, overwrite, executions_per_trial)\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mproject_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproject_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         )\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/base_tuner.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, oracle, hypermodel, directory, project_name, logger, overwrite)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_display\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuner_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_populate_initial_space\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moverwrite\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tuner_fname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/base_tuner.py\u001b[0m in \u001b[0;36m_populate_initial_space\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0;31m# Update the recored scopes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-52-3f7877bddbaa>\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m(hp)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Sample different number of layers with hp.Int\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dropout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0;31m# Sample different number of layers with hp.Int\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         model.add(layers.Dense(units=hp.Int('units_' + str(i),\n",
            "\u001b[0;31mTypeError\u001b[0m: 'float' object cannot be interpreted as an integer"
          ]
        }
      ],
      "source": [
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "tuner = kt.Hyperband(build_model,\n",
        "                     objective='val_loss',\n",
        "                     max_epochs=40,\n",
        "                     factor=2,\n",
        "                     hyperband_iterations=2,\n",
        "                     directory='my_dir_2',\n",
        "                     project_name='intro_to_kt')\n",
        "\n",
        "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
        "tuner.search(X_train_norm, y_train, epochs=30, validation_split=0.15,\n",
        "             batch_size=32, callbacks=[stop_early])\n",
        "\n",
        "# Get the optimal hyperparameters\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "print(best_hps.get_config())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0eb414e1",
      "metadata": {
        "id": "0eb414e1"
      },
      "outputs": [],
      "source": [
        "print(f\"Best learning rate: {best_hps.get('learning_rate')}\")\n",
        "print(f\"Best output activation function: {best_hps.get('output_activation')}\")\n",
        "print(f\"Best number of hidden layers: {best_hps.get('num_layers')}\")\n",
        "for i in range(best_hps.get('num_layers')):\n",
        "    print(f\"Number of units of hidden layer {i+1}: {best_hps.get('units_' + str(i))}\")\n",
        "    #print(f\"Dropout rate of hidden layer {i+1}: {best_hps.get('dp_' + str(i))}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ef4f3df",
      "metadata": {
        "id": "8ef4f3df"
      },
      "outputs": [],
      "source": [
        "model = tuner.hypermodel.build(best_hps)\n",
        "history = model.fit(X_train_norm, y_train, epochs=50, validation_split=0.15, callbacks=[stop_early])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1f46fac",
      "metadata": {
        "id": "a1f46fac"
      },
      "outputs": [],
      "source": [
        "results = model.evaluate(X_test_norm, y_test, verbose=1)\n",
        "print('Test Loss: {}'.format(results[0]))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "colab": {
      "name": "Regression_tuner.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}